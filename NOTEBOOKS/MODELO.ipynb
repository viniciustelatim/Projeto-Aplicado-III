{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01XJyKpdo6l5"
      },
      "source": [
        "#REQUISITOS NECESSÁRIOS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PmJk4-0IkV9K"
      },
      "outputs": [],
      "source": [
        "# @title BIBLIOTECAS\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from IPython import embed\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "import scipy.sparse as sp\n",
        "from tqdm import tqdm, trange\n",
        "import gzip\n",
        "import json\n",
        "from statistics import mean\n",
        "import math\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "    return version.split('+')[0]\n",
        "\n",
        "def format_cuda_version(version):\n",
        "    return 'cu' + version.replace('.', '')\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vSDLqiqA3e-F"
      },
      "outputs": [],
      "source": [
        "# @title TENSORBOARD\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)\n",
        "\n",
        "tb_fm = SummaryWriter(log_dir=f'{logs_base_dir}/{logs_base_dir}_FM/')\n",
        "tb_gcn = SummaryWriter(log_dir=f'{logs_base_dir}/{logs_base_dir}_FM_with_GCN/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wl0iG1oll6ZP"
      },
      "outputs": [],
      "source": [
        "# @title FUNÇÕES\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "\n",
        "def convert_to_numeric(values):\n",
        "    '''\n",
        "    Converte uma lista de valores em representações numéricas.\n",
        "    '''\n",
        "    unique_values = sorted(set(values))\n",
        "    mapping = {value: str(index).zfill(len(str(len(unique_values)))) for index, value in enumerate(unique_values)}\n",
        "    return [mapping[value] for value in values]\n",
        "\n",
        "def split_train_test(data, n_users):\n",
        "    '''\n",
        "    Separa os dados em conjuntos de treino e teste para cada usuário e remove os registros de timestamp.\n",
        "    '''\n",
        "    train_x, test_x = [], []\n",
        "    for u in trange(n_users, desc='separando treino/teste e removendo timestamp...'):\n",
        "        user_data = data[data[:, 0] == u]\n",
        "        sorted_data = user_data[user_data[:, -1].argsort()]\n",
        "        if len(sorted_data) == 1:\n",
        "            train_x.append(sorted_data[0][:-1])\n",
        "        else:\n",
        "            train_x.append(sorted_data[:-1][:, :-1])\n",
        "            test_x.append(sorted_data[-1][:-1])\n",
        "    return np.vstack(train_x), np.stack(test_x)\n",
        "\n",
        "def build_adj_mx(n_feat, data):\n",
        "    '''\n",
        "    Constrói uma matriz de adjacência a partir dos dados.\n",
        "    '''\n",
        "    train_mat = sp.dok_matrix((n_feat, n_feat), dtype=np.float32)\n",
        "    for x in tqdm(data, desc=f\"Construindo matrix de adjacência...\"):\n",
        "        train_mat[x[0], x[1]] = 1.0\n",
        "        train_mat[x[1], x[0]] = 1.0\n",
        "        if data.shape[1] > 2:\n",
        "            for idx in range(len(x[2:])):\n",
        "                train_mat[x[0], x[2 + idx]] = 1.0\n",
        "                train_mat[x[1], x[2 + idx]] = 1.0\n",
        "                train_mat[x[2 + idx], x[0]] = 1.0\n",
        "                train_mat[x[2 + idx], x[1]] = 1.0\n",
        "    return train_mat\n",
        "\n",
        "def ng_sample(data, dims, num_ng=4):\n",
        "    '''\n",
        "    Realiza amostragem negativa nos dados.\n",
        "    '''\n",
        "    rating_mat = build_adj_mx(dims[-1], data)\n",
        "    interactions = []\n",
        "    min_item, max_item = dims[0], dims[1]\n",
        "    for num, x in tqdm(enumerate(data), desc='performando amostragem negativa...'):\n",
        "        interactions.append(np.append(x, 1))\n",
        "        for t in range(num_ng):\n",
        "            j = np.random.randint(min_item, max_item)\n",
        "            while (x[0], j) in rating_mat or j == int(x[1]):\n",
        "                j = np.random.randint(min_item, max_item)\n",
        "            interactions.append(np.concatenate([[x[0], j], x[2:], [0]]))\n",
        "    return np.vstack(interactions), rating_mat\n",
        "\n",
        "def build_test_set(itemsnoninteracted, gt_test_interactions):\n",
        "    '''\n",
        "    Constrói o conjunto de teste a partir dos itens não interagidos e das interações verdadeiras de teste.\n",
        "    '''\n",
        "    test_set = []\n",
        "    for pair, negatives in tqdm(zip(gt_test_interactions, itemsnoninteracted), desc=\"CONSTRUINDO CONJUNTO DE TESTE...\"):\n",
        "        negatives = np.delete(negatives, np.where(negatives == pair[1]))\n",
        "        single_user_test_set = np.vstack([pair, ] * (len(negatives)+1))\n",
        "        single_user_test_set[:, 1][1:] = negatives\n",
        "        test_set.append(single_user_test_set.copy())\n",
        "    return test_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7Acy9i7pCcy"
      },
      "source": [
        "#PREPARANDO OS DADOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dA7N22RmgNlj"
      },
      "outputs": [],
      "source": [
        "# @title BAIXANDO OS DADOS\n",
        "\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/AMAZON_FASHION_5.json.gz\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/All_Beauty_5.json.gz\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Appliances_5.json.gz\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Gift_Cards_5.json.gz\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Industrial_and_Scientific_5.json.gz\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Luxury_Beauty_5.json.gz\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Magazine_Subscriptions_5.json.gz\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Software_5.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7uWMvvd4hkA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title DATASET\n",
        "\n",
        "file_paths = ['/content/AMAZON_FASHION_5.json.gz', '/content/All_Beauty_5.json.gz', '/content/Appliances_5.json.gz',\n",
        "              '/content/Gift_Cards_5.json.gz', '/content/Industrial_and_Scientific_5.json.gz', '/content/Luxury_Beauty_5.json.gz', '/content/Magazine_Subscriptions_5.json.gz',\n",
        "              '/content/Software_5.json.gz']\n",
        "\n",
        "dataframes = []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    a = getDF(file_path)\n",
        "    dataframes.append(a)\n",
        "\n",
        "df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "df = df[['reviewerID', 'asin', 'overall', 'unixReviewTime']]\n",
        "df.rename(columns={'reviewerID': 'user', 'asin': 'item', 'overall': 'rating', 'unixReviewTime': 'timestamp'}, inplace=True)\n",
        "df['user'] = convert_to_numeric(df['user'])\n",
        "df['item'] = convert_to_numeric(df['item'])\n",
        "df['user'] = df['user'].astype(int)\n",
        "df['item'] = df['item'].astype(int)\n",
        "df = df[df['user'].between(0, 5000)]\n",
        "df.reset_index(inplace=True)\n",
        "data = df[['user', 'item', 'timestamp']].astype('int32').to_numpy()\n",
        "\n",
        "add_dims=0\n",
        "for i in range(data.shape[1] - 1):\n",
        "    data[:, i] -= np.min(data[:, i])\n",
        "    data[:, i] += add_dims\n",
        "    add_dims = np.max(data[:, i]) + 1\n",
        "dims = np.max(data, axis=0) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xDpcxj7slD2A"
      },
      "outputs": [],
      "source": [
        "# @title SEPARANDO TREINO / TESTE\n",
        "\n",
        "train_x, test_x = split_train_test(data, dims[0])\n",
        "\n",
        "assert train_x.shape[0] + test_x.shape[0] == len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SrxaZjezlP_M"
      },
      "outputs": [],
      "source": [
        "# @title AMOSTRAGEM NEGATIVA\n",
        "\n",
        "train_x = train_x[:, :2]\n",
        "dims = dims[:2]\n",
        "\n",
        "train_x, rating_mat = ng_sample(train_x, dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tSnf98bmnvz2"
      },
      "outputs": [],
      "source": [
        "# @title CLASSE DO DATASET\n",
        "\n",
        "class PointData(Dataset):\n",
        "    def __init__(self, data, dims):\n",
        "        super(PointData, self).__init__()\n",
        "        self.interactions = data\n",
        "        self.dims = dims\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.interactions)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.interactions[index][:-1], self.interactions[index][-1]\n",
        "\n",
        "train_dataset = PointData(train_x, dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d8uodyBsn24y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title PREPARANDO O CONJUNTO DE TESTE PARA INFERÊNCIA\n",
        "\n",
        "zero_positions = np.asarray(np.where(rating_mat.A==0)).T\n",
        "\n",
        "items2compute = []\n",
        "for user in trange(dims[0]):\n",
        "    aux = zero_positions[zero_positions[:, 0] == user][:, 1]\n",
        "    items2compute.append(aux[aux >= dims[0]])\n",
        "\n",
        "test_x = build_test_set(items2compute, test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNOymqj5pJtC"
      },
      "source": [
        "#MODELO BASE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "aLRdHlBxyNF3"
      },
      "outputs": [],
      "source": [
        "# @title FM\n",
        "\n",
        "class FM_operation(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, reduce_sum=True):\n",
        "        super().__init__()\n",
        "        self.reduce_sum = reduce_sum\n",
        "\n",
        "    def forward(self, x):\n",
        "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
        "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
        "        ix = square_of_sum - sum_of_square\n",
        "        if self.reduce_sum:\n",
        "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
        "        return 0.5 * ix\n",
        "\n",
        "class FactorizationMachineModel(torch.nn.Module):\n",
        "    def __init__(self, field_dims, embed_dim):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(len(field_dims), 1)\n",
        "        self.embedding = torch.nn.Embedding(field_dims[-1], embed_dim)\n",
        "        self.fm = FM_operation(reduce_sum=True)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
        "\n",
        "    def forward(self, interaction_pairs):\n",
        "        out = self.linear(interaction_pairs.float()) + self.fm(self.embedding(interaction_pairs))\n",
        "        return out.squeeze(1)\n",
        "\n",
        "    def predict(self, interactions, device):\n",
        "        test_interactions = torch.from_numpy(interactions).to(dtype=torch.long, device=device)\n",
        "        output_scores = self.forward(test_interactions)\n",
        "        return output_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me7oO2JkCIgF"
      },
      "source": [
        "#PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iXOn2ECZy5Ni",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title MÉTRICAS\n",
        "\n",
        "def getHitRatio(recommend_list, gt_item):\n",
        "    if gt_item in recommend_list:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def getNDCG(recommend_list, gt_item):\n",
        "    idx = np.where(recommend_list == gt_item)[0]\n",
        "    if len(idx) > 0:\n",
        "        return math.log(2)/math.log(idx+2)\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W41PDoPZyzeN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title TREINO E TESTE\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = []\n",
        "\n",
        "    for i, (interactions, targets) in enumerate(data_loader):\n",
        "        interactions = interactions.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        predictions = model(interactions)\n",
        "\n",
        "        loss = criterion(predictions, targets.float())\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "    return mean(total_loss)\n",
        "\n",
        "\n",
        "def test(model, test_x, device, topk=10):\n",
        "    model.eval()\n",
        "\n",
        "    HR, NDCG = [], []\n",
        "    for user_test in test_x:\n",
        "        gt_item = user_test[0][1]\n",
        "        predictions = model.predict(user_test, device)\n",
        "        _, indices = torch.topk(predictions, topk)\n",
        "        recommend_list = user_test[indices.cpu().detach().numpy()][:, 1]\n",
        "\n",
        "        HR.append(getHitRatio(recommend_list, gt_item))\n",
        "        NDCG.append(getNDCG(recommend_list, gt_item))\n",
        "    return mean(HR), mean(NDCG)\n",
        "\n",
        "\n",
        "def train_and_test(topk, model, optimizer, criterion, data_loader, device, test_x, tb):\n",
        "    for epoch_i in trange(10):\n",
        "        train_loss = train_one_epoch(model, optimizer, data_loader, criterion, device)\n",
        "        hr, ndcg = test(model, test_x, device, topk=topk)\n",
        "        tb.add_scalar('train/loss', train_loss, epoch_i)\n",
        "        tb.add_scalar('eval/HR@{topk}', hr, epoch_i)\n",
        "        tb.add_scalar('eval/NDCG@{topk}', ndcg, epoch_i)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "4QFdacqUy-HD"
      },
      "outputs": [],
      "source": [
        "# @title OPTIMIZER\n",
        "\n",
        "dims = train_dataset.dims\n",
        "model = FactorizationMachineModel(dims, 32).to(device)\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "data_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RmVN8lA6zGn9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title TREINAMENTO DO MODELO BASE\n",
        "train_and_test(10, model, optimizer, criterion, data_loader, device, test_x, tb_fm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5vpi7BpwrDS"
      },
      "source": [
        "#MODELO GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "kmWkuaW94DqY"
      },
      "outputs": [],
      "source": [
        "# @title PYTORCH GEOMETRIC\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "AVTC8kJ-4FCu"
      },
      "outputs": [],
      "source": [
        "# @title MATRIX ESPARSA\n",
        "\n",
        "from torch_geometric.utils import from_scipy_sparse_matrix\n",
        "from scipy.sparse import identity\n",
        "\n",
        "edge_idx, edge_attr = from_scipy_sparse_matrix(rating_mat)\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "X = sparse_mx_to_torch_sparse_tensor(identity(rating_mat.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "SPLm1-wz4G76"
      },
      "outputs": [],
      "source": [
        "# @title CAMADA GCN\n",
        "\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "\n",
        "class GCELayer(torch.nn.Module):\n",
        "    def __init__(self, field_dims, embed_dim, features, train_mat, attention=False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.A = train_mat\n",
        "        self.features = features\n",
        "        if attention:\n",
        "            self.GCN_module = GATConv(int(field_dims), embed_dim, heads=8, dropout=0.4)\n",
        "        else:\n",
        "            self.GCN_module = GCNConv(field_dims, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        return self.GCN_module(self.features, self.A)[x]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rl7YPM7N4MH3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title FM + GCN\n",
        "\n",
        "class FactorizationMachineModel_withGCN(torch.nn.Module):\n",
        "    def __init__(self, field_dims, embed_dim, X, A, attention=False):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(len(field_dims), 1)\n",
        "        self.embedding = GCELayer(field_dims[-1], embed_dim, X, A, attention=attention)\n",
        "        self.fm = FM_operation(reduce_sum=True)\n",
        "\n",
        "    def forward(self, interaction_pairs):\n",
        "        out = self.linear(interaction_pairs.float()) + self.fm(self.embedding(interaction_pairs))\n",
        "        return out.squeeze(1)\n",
        "\n",
        "    def predict(self, interactions, device):\n",
        "        test_interactions = torch.from_numpy(interactions).to(dtype=torch.long, device=device)\n",
        "        output_scores = self.forward(test_interactions)\n",
        "        return output_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CfWQDzw04TN6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title OTIMIZADOR\n",
        "model_gcn = FactorizationMachineModel_withGCN(train_dataset.dims,\n",
        "                                              32,\n",
        "                                              X.to(device),\n",
        "                                              edge_idx.to(device),\n",
        "                                              ).to(device)\n",
        "\n",
        "gcn_criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "gcn_optimizer = torch.optim.Adam(params=model_gcn.parameters(), lr=0.01)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5aNDkSPU4UE5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title TREINAMENTO DO MODELO GCN\n",
        "train_and_test(10, model_gcn, gcn_optimizer, gcn_criterion, data_loader, device, test_x, tb_gcn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf1AhnzA4ZVC"
      },
      "source": [
        "#RESULTADOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgDGpwb5zRpj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title VISUALIZANDO RESULTADOS COM TENSORBOARD\n",
        "%tensorboard --logdir runs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}